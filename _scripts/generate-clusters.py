#!/usr/bin/env python3
"""Generate cluster MOC (Map of Content) pages for cross-dimensional browse.

Reads all 10,000 Mibera YAML frontmatter files and generates Markdown pages
for every non-empty intersection of high-value dimension pairs:
  - archetype × ancestor
  - archetype × element
  - ancestor × element

Output: browse/clusters/{pair_type}/{slug-a}-x-{slug-b}.md
Index:  browse/clusters/index.md
"""

import glob
import os
import yaml
from collections import defaultdict
from datetime import datetime, timezone

MIBERA_DIR = "miberas"
OUTPUT_DIR = "browse/clusters"
TIMESTAMP = datetime.now(timezone.utc).strftime("%Y-%m-%dT%H:%M:%SZ")
MAX_INLINE_LINKS = 50

# Dimension pairs to generate
PAIRS = [
    {
        "id": "archetype-ancestor",
        "dim_a": "archetype",
        "dim_b": "ancestor",
        "label_a": "Archetype",
        "label_b": "Ancestor",
        "link_a": lambda slug: f"../../../core-lore/archetypes.md#{slug}",
        "link_b": lambda slug: f"../../../core-lore/ancestors/{slug}.md",
    },
    {
        "id": "archetype-element",
        "dim_a": "archetype",
        "dim_b": "element",
        "label_a": "Archetype",
        "label_b": "Element",
        "link_a": lambda slug: f"../../../core-lore/archetypes.md#{slug}",
        "link_b": lambda _: f"../../../browse/by-element.md",
    },
    {
        "id": "ancestor-element",
        "dim_a": "ancestor",
        "dim_b": "element",
        "label_a": "Ancestor",
        "label_b": "Element",
        "link_a": lambda slug: f"../../../core-lore/ancestors/{slug}.md",
        "link_b": lambda _: f"../../../browse/by-element.md",
    },
]


def slugify(name):
    """Convert display name to file slug."""
    if not name:
        return ""
    s = name.lower()
    s = s.replace("\u2019", "")  # right single quote
    s = s.replace("'", "")
    s = s.replace(".", "")
    s = s.replace(" ", "-")
    s = s.replace("/", "-")
    return s


def load_mibera_data():
    """Load frontmatter from all Mibera files."""
    miberas = []
    for filepath in sorted(glob.glob(os.path.join(MIBERA_DIR, "*.md"))):
        basename = os.path.basename(filepath)
        if basename == "index.md":
            continue
        try:
            with open(filepath, "r") as f:
                content = f.read()
            if not content.startswith("---"):
                continue
            end = content.index("---", 3)
            fm = yaml.safe_load(content[3:end])
            if fm and isinstance(fm, dict):
                mibera_id = fm.get("id")
                if mibera_id is not None:
                    miberas.append({
                        "id": int(mibera_id),
                        "archetype": fm.get("archetype", ""),
                        "ancestor": fm.get("ancestor", ""),
                        "element": fm.get("element", ""),
                    })
        except Exception as e:
            print(f"  WARNING: Error reading {filepath}: {e}")
    return miberas


def format_mibera_links(ids):
    """Format Mibera IDs as inline links with truncation."""
    links = []
    for mid in sorted(ids)[:MAX_INLINE_LINKS]:
        padded = f"{mid:04d}"
        links.append(f"[#{padded}](../../../miberas/{padded}.md)")

    result = " • ".join(links)
    remaining = len(ids) - MAX_INLINE_LINKS
    if remaining > 0:
        result += f" • *...and {remaining} more*"
    return result


def generate_cluster_page(pair, val_a, val_b, ids):
    """Generate a single cluster page."""
    slug_a = slugify(val_a)
    slug_b = slugify(val_b)
    link_a = pair["link_a"](slug_a)
    link_b = pair["link_b"](slug_b)
    count = len(ids)

    content = f"""<!-- generated: {TIMESTAMP} by _scripts/generate-clusters.py -->

# {val_a} × {val_b}

*{pair["label_a"]}: {val_a} | {pair["label_b"]}: {val_b}*

**{count:,} Miberas** in this cluster.

[Learn about {val_a} →]({link_a}) | [Learn about {val_b} →]({link_b})

{format_mibera_links(ids)}

---

*Generated by `_scripts/generate-clusters.py`*
"""
    return content


def generate_index(all_clusters):
    """Generate the cluster index page."""
    lines = [
        f"<!-- generated: {TIMESTAMP} by _scripts/generate-clusters.py -->",
        "",
        "# Cluster Browse",
        "",
        "*Cross-dimensional views of the 10,000 Miberas. Each cluster page shows all Miberas matching a specific combination of traits.*",
        "",
        "---",
        "",
    ]

    for pair in PAIRS:
        pair_id = pair["id"]
        clusters = all_clusters.get(pair_id, [])
        if not clusters:
            continue

        # Sort by count descending
        clusters_sorted = sorted(clusters, key=lambda c: c["count"], reverse=True)
        largest = clusters_sorted[0]
        smallest = clusters_sorted[-1]

        lines.append(f"## {pair['label_a']} × {pair['label_b']}")
        lines.append("")
        lines.append(f"*{len(clusters_sorted)} clusters | Largest: {largest['name']} ({largest['count']:,}) | Smallest: {smallest['name']} ({smallest['count']:,})*")
        lines.append("")
        lines.append("| Cluster | Miberas |")
        lines.append("|---------|---------|")

        for c in clusters_sorted:
            lines.append(f"| [{c['name']}]({c['path']}) | {c['count']:,} |")

        lines.append("")
        lines.append("---")
        lines.append("")

    lines.append("*Generated by `_scripts/generate-clusters.py`*")
    lines.append("")
    return "\n".join(lines)


def main():
    print("Loading Mibera data...")
    miberas = load_mibera_data()
    print(f"  Loaded {len(miberas)} Miberas")

    all_clusters = {}
    total_pages = 0

    for pair in PAIRS:
        pair_id = pair["id"]
        dim_a = pair["dim_a"]
        dim_b = pair["dim_b"]

        print(f"\nGenerating {pair['label_a']} × {pair['label_b']} clusters...")

        # Build lookup: (val_a, val_b) -> [mibera_ids]
        clusters = defaultdict(list)
        for m in miberas:
            va = m.get(dim_a, "")
            vb = m.get(dim_b, "")
            if va and vb:
                clusters[(va, vb)].append(m["id"])

        # Create output directory
        pair_dir = os.path.join(OUTPUT_DIR, pair_id)
        os.makedirs(pair_dir, exist_ok=True)

        pair_cluster_info = []
        for (va, vb), ids in sorted(clusters.items()):
            slug_a = slugify(va)
            slug_b = slugify(vb)
            filename = f"{slug_a}-x-{slug_b}.md"
            filepath = os.path.join(pair_dir, filename)

            content = generate_cluster_page(pair, va, vb, ids)
            with open(filepath, "w") as f:
                f.write(content)

            pair_cluster_info.append({
                "name": f"{va} × {vb}",
                "path": f"{pair_id}/{filename}",
                "count": len(ids),
            })
            total_pages += 1

        all_clusters[pair_id] = pair_cluster_info
        print(f"  Generated {len(pair_cluster_info)} cluster pages")

    # Generate index
    print(f"\nGenerating index page...")
    index_content = generate_index(all_clusters)
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    with open(os.path.join(OUTPUT_DIR, "index.md"), "w") as f:
        f.write(index_content)

    print(f"\nDone!")
    print(f"  Total cluster pages: {total_pages}")
    print(f"  Index: {OUTPUT_DIR}/index.md")
    print(f"  Directories: {', '.join(p['id'] for p in PAIRS)}")


if __name__ == "__main__":
    main()
